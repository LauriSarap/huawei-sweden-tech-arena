{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f50ad8b",
   "metadata": {},
   "source": [
    "# SVD Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8434ff",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "### Diagonal Matrix\n",
    "\n",
    "**General**\n",
    "$$\n",
    "D = \\begin{pmatrix}\n",
    "d_1 & 0 & 0 \\\\\n",
    "0 & d_2 & 0 \\\\\n",
    "0 & 0 & d_3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "* Determinant - product of diagonal elements $\\det(D) = d_1 \\cdot d_2 \\cdot d_3$.\n",
    "* Inverse - if all elements are non-zero, inverse is obtained by taking the reciprocal of each diagonal element\n",
    "$$\n",
    "D^{-1} = \\begin{pmatrix}\n",
    "\\frac{1}{d_1} & 0 & 0 \\\\\n",
    "0 & \\frac{1}{d_2} & 0 \\\\\n",
    "0 & 0 & \\frac{1}{d_3}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* Multiplciation\n",
    "    * $AD$ - scales thr rows of $A$ by the diagonal elements of $D$.\n",
    "    * $DA$ - scales the columns of $A$ by the diagonal elements of $D$.\n",
    "* Transposition - same as the original matrix.\n",
    "* Power - raising to a power is done element-wise. $D^k$ would have $d_1^k, d_2^k, d_3^k$ on the diagonal.\n",
    "\n",
    "**Geometric Interpretation**\n",
    "* Scales a vector $(x,y,z)$ by the diagonal elements.\n",
    "* Scaling operations stretches or shirnks the vector along each axis independently.\n",
    "\n",
    "### Orthogonal Matrix\n",
    "\n",
    "**General**\n",
    "* Square matrix $Q$ is orthogonal if the following holds:\n",
    "$$\n",
    "Q^T = Q^{-1}\n",
    "$$\n",
    "* Following properties hold for orthogonal matrices:\n",
    "$$\n",
    "Q^T Q = I \\\\\n",
    "Q Q^T = I\n",
    "$$\n",
    "\n",
    "* Determinant\n",
    "   * +1 or -1\n",
    "   * $\\det(Q) = 1$ - represents a rotation.\n",
    "    * $\\det(Q) = -1$ - represents a reflection.\n",
    "* Example 1: Rotation matrix in 2D\n",
    "$$\n",
    "Q = \\begin{pmatrix}\n",
    "\\cos(\\theta) & -\\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta)\n",
    "\\end{pmatrix} \\\\\n",
    "\n",
    "\\det(Q) = \\cos^2(\\theta) + \\sin^2(\\theta) = 1\n",
    "$$\n",
    "* Example 2: Reflection matrix in 2D\n",
    "$$\n",
    "Q = \\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & -1\n",
    "\\end{pmatrix} \\\\\n",
    "\\det(Q) = 1 \\cdot (-1) - 0 \\cdot 0 = -1\n",
    "$$\n",
    "\n",
    "**Geometric Interpretation**\n",
    "* Orthogonal matrix Q preserves the length of vectors and angles between them.\n",
    "* As the Euclidean norm (length) is given as:\n",
    "$$\n",
    "||\\mathbf{v}|| = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}\n",
    "$$\n",
    "* Length is preserved\n",
    "$$\n",
    "||Q\\mathbf{v}|| = ||\\mathbf{v}||\n",
    "$$\n",
    "* Angle is also preserved\n",
    "$$\n",
    "(Q\\mathbf{u}) (Q\\mathbf{v}) = \\mathbf{u} \\mathbf{v}\n",
    "$$\n",
    "* Orthogonal matrices represent rigid transformations - rotations and reflections that do not stretch of distort the space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540f14d",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)\n",
    "\n",
    "### SVD definition\n",
    "* SVD - a matrix factorization technique that decomposes a $m \\times n$ matrix $A$ into three matrices:\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "* Components of the transformation:\n",
    "    * $U$ - $m \\times m$ orthogonal matrix whose columns are the **left singular vectors** of $A$.\n",
    "    * $\\Sigma$ - $m \\times n$ diagonal matrix with non-negative real numbers. There are the **singular values** of $A$ on the diagonal in descending order.\n",
    "    * $V$ - $n \\times n$ orthogonal matrix whose columns are the **right singular vectors** of $A$. V is transposed in the decomposition.\n",
    "\n",
    "### Components of SVD\n",
    "\n",
    "**Singular Values**\n",
    "* Represent the \"importance\" or \"magnitude\" of each dimension in the transformation defined by $A$.\n",
    "* Quantify how much $A$ stretches or compresses vectors along the directions defined by the singular vectors.\n",
    "\n",
    "**Singular Vectors**\n",
    "* Singular vectors define the directions in which A acts as the scaling transformation, with singular values specifying the scaling factors.\n",
    "* Left singular vectors ($U$) - eigenvectors of $AA^T$. Form an orthonormal basis for the column space of $A$.\n",
    "* Right singular vectors ($V$) - eigenvectors of $A^TA$. Form an orthonormal basis for the row space of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edc97a",
   "metadata": {},
   "source": [
    "## Frobenius Norm\n",
    "* Frobenius norm - a way to the total magnitude/energy of a matrix.\n",
    "* Square every element, sum them up, and take the square root.\n",
    "$$\n",
    "||A||_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |a_{ij}|^2} = \\sqrt{\\sigma_1^2+ \\sigma_2^2 + \\cdots + \\sigma_r^2}\n",
    "$$\n",
    "* In SVD helps measure how well a low-rank approximation (so few singular values) captures the original matrix.\n",
    "* $\\Sigma $ is truncated to keep only the largest singular values, giving $A_k$ and minimizing the Frobenius norm of the error\n",
    "$$\n",
    "||A - A_k||_F\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5ab6b",
   "metadata": {},
   "source": [
    "## Computation of SVD\n",
    "\n",
    "**Computational Complexity**\n",
    "* $m \\times n$ matrix $A$\n",
    "* Where $m \\geq n$\n",
    "* SVD has complexity if of\n",
    "$$\n",
    "O(mn^2)\n",
    "$$\n",
    "* Computationally very expensive for large matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6089124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
